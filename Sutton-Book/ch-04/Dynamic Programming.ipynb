{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#2595bc\">Dynamic Programming</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter  1\n",
      "Policy Eval\n",
      "counter  2\n",
      "Policy Eval\n",
      "counter  3\n",
      "Policy improvement\n",
      "Policy improv took :  97.17668843269348\n",
      "Policy Eval\n",
      "counter  4\n",
      "Policy improvement\n",
      "Policy improv took :  104.92326855659485\n",
      "Policy Eval\n",
      "counter  5\n",
      "Policy improvement\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-40a38388ee4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                         \u001b[0maction_returns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                         \u001b[0maction_returns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-40a38388ee4d>\u001b[0m in \u001b[0;36mexpected_return\u001b[0;34m(state, action, state_value)\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mtemp_n_cars_in_second\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_cars_in_second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mtemp_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mtemp_n_cars_in_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_n_cars_in_first\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreturned_cars_in_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                     \u001b[0mtemp_n_cars_in_second\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_n_cars_in_second\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreturned_cars_in_second\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mtemp_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturned_cars_in_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_return_first\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m                                 \u001b[0mpoisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturned_cars_in_second\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_return_second\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#Jacks Car rental \n",
    "availability_rent = 10\n",
    "moving_cost = 2\n",
    "\n",
    "mean_request_first = 3\n",
    "mean_request_second = 4\n",
    "\n",
    "mean_return_first = 3\n",
    "mean_return_second = 2\n",
    "\n",
    "max_cars = 20\n",
    "max_car_move = 5\n",
    "\n",
    "no_of_states = (max_cars+1)*(max_cars+1)\n",
    "no_of_possible_actions = (2*max_car_move + 1) #11\n",
    "\n",
    "actions = np.arange(-max_car_move,max_car_move+1,1)\n",
    "\n",
    "discount = .9\n",
    "\n",
    "\n",
    "# current policy\n",
    "policy = np.zeros((max_cars + 1, max_cars + 1))\n",
    "\n",
    "# current state value\n",
    "state_value = np.zeros((max_cars + 1, max_cars + 1))\n",
    "\n",
    "\n",
    "#create an array of dicts\n",
    "next_states = []\n",
    "\n",
    "#Calculation of poisson takes a lot of time\n",
    "\n",
    "lookup_poisson = dict()\n",
    "def poisson(n,lambd):\n",
    "    global lookup_poisson\n",
    "    if n-lambd>=6:\n",
    "        return 0\n",
    "    else:\n",
    "        key = lambd*10 + n\n",
    "        if key not in lookup_poisson.keys():\n",
    "            lookup_poisson[key] = math.exp(-lambd) * pow(lambd, n) / math.factorial(n)\n",
    "        return lookup_poisson[key]\n",
    "\n",
    "def expected_return(state, action, state_value):\n",
    "    # initailize total return\n",
    "    returns = 0.0\n",
    "\n",
    "    # cost for moving cars\n",
    "    returns -= moving_cost * abs(action)\n",
    "\n",
    "    # go through all possible rental requests\n",
    "    for rent_request_first in range(0, mean_request_first+6):\n",
    "        for rent_request_second in range(0, mean_request_second+6):\n",
    "            # moving cars\n",
    "            n_cars_in_first = int(min(state[0] - action, max_cars))\n",
    "            n_cars_in_second = int(min(state[1] + action, max_cars))\n",
    "\n",
    "            # valid rental requests should be less than actual # of cars\n",
    "            cars_rented_in_first = min(n_cars_in_first, rent_request_first)\n",
    "            cars_rented_in_second = min(n_cars_in_second, rent_request_second)\n",
    "\n",
    "            # get credits for renting\n",
    "            reward = (cars_rented_in_first + cars_rented_in_second) * availability_rent\n",
    "            n_cars_in_first -= cars_rented_in_first\n",
    "            n_cars_in_second -= cars_rented_in_second\n",
    "\n",
    "            # probability for current combination of rental requests\n",
    "            prob = poisson(rent_request_first, mean_request_first) * \\\n",
    "                         poisson(rent_request_second, mean_request_second)\n",
    "\n",
    "            \n",
    "           \n",
    "            placeholder_n_cars_in_first  = n_cars_in_first\n",
    "            placeholder_n_cars_in_second = n_cars_in_second\n",
    "            placeholder_prob = prob\n",
    "            \n",
    "            for returned_cars_in_first in range(0, mean_return_first+6):\n",
    "                for returned_cars_in_second in range(0, mean_request_second+6):\n",
    "                    \n",
    "                    temp_n_cars_in_first = n_cars_in_first\n",
    "                    temp_n_cars_in_second = n_cars_in_second\n",
    "                    temp_prob = prob\n",
    "                    temp_n_cars_in_first = min(temp_n_cars_in_first + returned_cars_in_first, max_cars)\n",
    "                    temp_n_cars_in_second= min(temp_n_cars_in_second + returned_cars_in_second, max_cars)\n",
    "                    temp_prob = poisson(returned_cars_in_first, mean_return_first) * \\\n",
    "                                poisson(returned_cars_in_second, mean_return_second) * prob\n",
    "                    returns += temp_prob * (reward + discount * state_value[temp_n_cars_in_first, temp_n_cars_in_second])\n",
    "    return returns\n",
    "\n",
    "\n",
    "\n",
    "new_state_value = np.zeros((max_cars + 1, max_cars + 1))\n",
    "improve_policy = False\n",
    "#policyImprovementInd = 0\n",
    "counter = 0\n",
    "\n",
    "aa = time.time()\n",
    "while True:\n",
    "    \n",
    "    counter += 1\n",
    "    print ('counter ',counter)\n",
    "    if improve_policy == True:\n",
    "        alpha = time.time()\n",
    "        # start policy improvement\n",
    "        \n",
    "        #print('Policy improvement', policyImprovementInd)\n",
    "        print('Policy improvement')\n",
    "        #policyImprovementInd += 1\n",
    "        new_policy = np.zeros((max_cars + 1, max_cars + 1))\n",
    "        for i in range(max_cars+1):\n",
    "            for j in range(max_cars+1):\n",
    "                action_returns = []\n",
    "                # go through all actions and select the best one\n",
    "                for action in actions:\n",
    "                    if (action >= 0 and i >= action) or (action < 0 and j >= abs(action)):\n",
    "                        action_returns.append(expected_return([i, j], action, state_value))\n",
    "                    else:\n",
    "                        action_returns.append(-float('inf'))\n",
    "                best_action = np.argmax(action_returns)\n",
    "                new_policy[i, j] = actions[best_action]\n",
    "\n",
    "        # if policy is stable\n",
    "        policyChanges = np.sum(new_policy != policy)\n",
    "        #print('Policy for', policyChanges, 'states changed')\n",
    "        beta = time.time()\n",
    "        print(\"Policy improv took : \",beta-alpha)\n",
    "        if policyChanges == 0:\n",
    "            policy = new_policy\n",
    "            break\n",
    "            \n",
    "        policy = new_policy\n",
    "        improve_policy = False\n",
    "\n",
    "    # start policy evaluation\n",
    "    print('Policy Eval')\n",
    "    for i in range(max_cars+1):\n",
    "            for j in range(max_cars+1):\n",
    "                new_state_value[i, j] = expected_return([i, j], policy[i, j], state_value)\n",
    "    if np.sum(np.abs(new_state_value - state_value)) < 1e-4:\n",
    "        state_value = new_state_value\n",
    "        improve_policy = True\n",
    "        continue\n",
    "    state_value = new_state_value\n",
    "    improve_policy = False\n",
    "bb = time.time()\n",
    "\n",
    "print('The whole process took : ',bb-aa)\n",
    "print(policy)\n",
    "print(state_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5, -4, -3, -2, -1,  0,  1,  2,  3,  4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
